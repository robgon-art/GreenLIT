{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GreenLIT",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/robgon-art/GreenLIT/blob/main/GreenLIT.ipynb",
      "authorship_tag": "ABX9TyODDHtBwyRNuDtvgHUhszR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/GreenLIT/blob/main/GreenLIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GreenLIT: Using GPT-J with Multi-Task Learning to Create New Screenplays**\n",
        "## How to fine-tune an ML model to create TV shows and movies with new titles, plot summaries, and scripts\n",
        "\n",
        "![ReGEN Cover Image](https://raw.githubusercontent.com/robgon-art/ReGEN/main/cover_med.jpg)\n",
        "\n",
        "Photo by [Tech Daily](https://unsplash.com/photos/PGuCnUzsRSM) on [Unsplash](https://unsplash.com/)</br>\n",
        "\n",
        "**By Robert. A Gonsalves**</br>\n",
        "You can see my article on [Medium](https://towardsdatascience.com/greenlit-using-gpt-j-with-multi-task-learning-to-create-new-screenplays-54a2d04f761c#c07d-fe51a662351d)."
      ],
      "metadata": {
        "id": "FEWG2iBgiGxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize the System\n",
        "!nvidia-smi\n",
        "!gdown 103xsaUZlukpbOu-h2AEyAyQHwMHwgRbk\n",
        "# !pip install transformers bitsandbytes-cuda111 wikipedia\n",
        "!pip install transformers==4.22.2\n",
        "!pip install bitsandbytes==0.34.0\n",
        "!pip install wikipedia\n",
        "\n",
        "from torch import nn\n",
        "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
        "from torch.cuda.amp import custom_fwd, custom_bwd\n",
        "import torch.nn.functional as F\n",
        "import wikipedia\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "\n",
        "def check_in_wiki(name):\n",
        "  name_parts = name.split()\n",
        "  wiki_results = wikipedia.search(name)\n",
        "  for w in wiki_results:\n",
        "    w = w.lower()\n",
        "    match_all_parts = True\n",
        "    for n in name_parts:\n",
        "      n = n.lower()\n",
        "      if n == \"the\" or n == \"a\":\n",
        "        continue\n",
        "      if n not in w:\n",
        "        match_all_parts = False\n",
        "        break\n",
        "    if match_all_parts:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "class FrozenBNBLinear(nn.Module):\n",
        "    def __init__(self, weight, absmax, code, bias=None):\n",
        "        assert isinstance(bias, nn.Parameter) or bias is None\n",
        "        super().__init__()\n",
        "        self.out_features, self.in_features = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "        self.bias = bias\n",
        " \n",
        "    def forward(self, input):\n",
        "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output\n",
        " \n",
        "    @classmethod\n",
        "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
        "        return cls(weights_int8, *state, linear.bias)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
        " \n",
        "class DequantizeAndLinear(torch.autograd.Function): \n",
        "    @staticmethod\n",
        "    @custom_fwd\n",
        "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
        "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
        "        ctx._has_bias = bias is not None\n",
        "        return F.linear(input, weights_deq, bias)\n",
        " \n",
        "    @staticmethod\n",
        "    @custom_bwd\n",
        "    def backward(ctx, grad_output: torch.Tensor):\n",
        "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
        "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
        "        # grad_output: [*batch, out_features]\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        grad_input = grad_output @ weights_deq\n",
        "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
        "        return grad_input, None, None, None, grad_bias\n",
        "\n",
        "class FrozenBNBEmbedding(nn.Module):\n",
        "    def __init__(self, weight, absmax, code):\n",
        "        super().__init__()\n",
        "        self.num_embeddings, self.embedding_dim = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        " \n",
        "    def forward(self, input, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            # note: both quantuized weights and input indices are *not* differentiable\n",
        "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
        "            output = F.embedding(input, weight_deq, **kwargs)\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output \n",
        " \n",
        "    @classmethod\n",
        "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
        "        return cls(weights_int8, *state)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
        " \n",
        "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
        "    assert chunk_size % 4096 == 0\n",
        "    code = None\n",
        "    chunks = []\n",
        "    absmaxes = []\n",
        "    flat_tensor = matrix.view(-1)\n",
        "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
        "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
        "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
        "        chunks.append(quantized_chunk)\n",
        "        absmaxes.append(absmax_chunk)\n",
        " \n",
        "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
        "    absmax = torch.cat(absmaxes)\n",
        "    return matrix_i8, (absmax, code)\n",
        " \n",
        " \n",
        "def convert_to_int8(model):\n",
        "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
        "    for module in list(model.modules()):\n",
        "        for name, child in module.named_children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                print(name, child)\n",
        "                setattr( \n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBLinear(\n",
        "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                        bias=child.bias,\n",
        "                    ),\n",
        "                )\n",
        "            elif isinstance(child, nn.Embedding):\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBEmbedding(\n",
        "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        convert_to_int8(self.attn)\n",
        "        convert_to_int8(self.mlp)\n",
        "\n",
        "\n",
        "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "        \n",
        "\n",
        "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock  # monkey-patch GPT-J\n",
        "\n",
        "gpt = torch.load(\"/content/GreenLIT_new.pt\",  map_location=torch.device('cuda'))\n",
        "gpt.eval()\n",
        "\n",
        "import re\n",
        "import textwrap\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "nn2aaM6rwUnR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Titles and Summaries\n",
        "genre = 'crime drama' #@param {type:\"string\"}\n",
        "theme = 'cryptocurrency' #@param {type:\"string\"}\n",
        "\n",
        "prompt = \"GENRE: \" + genre + \" THEME: \" + theme + \"TITLE:\"\n",
        "with torch.no_grad():\n",
        "  prompt_tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "  sample_outputs = gpt.generate(prompt_tokens, max_length=80, do_sample=True, \n",
        "    temperature=0.8, pad_token_id=tokenizer.eos_token_id, num_return_sequences=40)\n",
        "\n",
        "titles = []\n",
        "summaries = []\n",
        "count = 1\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  results = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "  results = results.replace(\"\\n\", \" \")\n",
        "  genre = re.search('GENRE:(.*)THEME:', results).group(1).strip()\n",
        "  title = re.search('TITLE:(.*)SUMMARY:', results).group(1).strip()\n",
        "\n",
        "  already_done = check_in_wiki(title)\n",
        "  alpha = re.sub('[^a-zA-Z]+', '', title)\n",
        "\n",
        "  if len(alpha) < 3 or already_done:\n",
        "    continue\n",
        "\n",
        "  summary = re.search('SUMMARY:(.*)', results).group(1).strip()\n",
        "  titles.append(title)\n",
        "  summaries.append(summary)\n",
        "\n",
        "  out = str(count).zfill(2) + \" \" + title + \" - \" + summary\n",
        "  wrapped = textwrap.fill(out, width=150, subsequent_indent=\"   \")\n",
        "  print(wrapped)\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "m3i4jeDMd6Yg",
        "outputId": "bbb4e4a3-4f0d-482a-f054-688b9522e925"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01 The Internet’s Own Boy - A teenage boy from the “Deep Web”, a dark corner of the internet, develops a computer virus capable of manipulating the\n",
            "   stock market.\n",
            "02 The Dark Web: The Untold Story - Over the course of two years, filmmaker James Lee and his crew investigate a massive darknet-based child\n",
            "   pornography ring that has been operating for over a decade.\n",
            "03 The Crypto Queen - Three generations of women face life as prisoners of a ruthless crime lord when the government finally catches up to his\n",
            "   fortune.\n",
            "04 Satoshi's Brain - A darkly comic tale of an eccentric billionaire and his quest to win back control of Bitcoin from a rival.\n",
            "05 CryptoHustle - A young man, struggling to get by in an unpredictable world, is lured into a game of cryptocurrency hustling by a pair of con\n",
            "   artists.\n",
            "06 Satoshi's Anonymous - Two young men embark on a global journey to find the true identity of the creator of Bitcoin.\n",
            "07 Bitcoin Heist - A desperate man plots with a group of criminals to rob the rich and steal BTC.\n",
            "08 Cryptomania - A struggling, disheartened IT worker decides to launch a startup cryptocurrency venture. What starts as an attempt to save his\n",
            "   marriage soon morphs into something much more sinister.\n",
            "09 The Black Bailer - The Black Bailer is another film in which I was honored to participate. It was inspired by the true story of a man who was\n",
            "   released to a group home as a teen but had a tendency to become aggressive if things were not going his way.\n",
            "10 The CryptKiller - A small-time drug dealer has a run of bad luck with the law as he struggles to pay off his debts and keep his daughter safe.\n",
            "11 White Fang (4K UHD) - In the year 1906, a group of miners in the Yukon Territory, Canada, are struggling to survive in the unforgiving Arctic\n",
            "   conditions. Amid this struggle to survive, a young woman learns to fight to protect her family from a ruthless killer\n",
            "12 The Crypto-Jihad - A young man, a bitcoin enthusiast and the CEO of a blockchain startup, is recruited by a powerful crypto-expert to infiltrate a\n",
            "   shady cryptocurrency project.\n",
            "13 The Cryptography of Time - The story of three young men and a woman who begin to discover that through the use of Bitcoin, they are able to see\n",
            "   into the past.\n",
            "14 Bitcoin: The End Of Money As We Know It - Three stories about digital money intersect in this film that explores the rise of bitcoin, the evolution\n",
            "   of the blockchain, and the evolution of our financial system.\n",
            "15 The Secret Life of Bitcoin - A computer programmer with a passion for Bitcoin who finds herself embroiled in a high-stakes money laundering scheme.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a Title and Create a Script\n",
        "\n",
        "choice = 4 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "choice -= 1\n",
        "\n",
        "if choice >= len(titles):\n",
        "  print(\"Choose between 1 and \" + str(len(titles)))\n",
        "else:\n",
        "  title = titles[choice]\n",
        "  summary = summaries[choice]\n",
        "  print(choice+1, title)\n",
        "\n",
        "  prompt = \"TITLE: \" + title + \" SUMMARY: \" + summary + \" SCRIPT:\\n[Scene:\"\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    prompt_tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "    sample_outputs = gpt.generate(prompt_tokens, max_length=480, do_sample=True, \n",
        "      top_k=50, pad_token_id=tokenizer.eos_token_id,\n",
        "      num_return_sequences=1)\n",
        "    results = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "    results = results.strip()\n",
        "    print(\"\\n[Scene:\" + results[len(prompt):])"
      ],
      "metadata": {
        "id": "tkLOMdD8M2xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "43cfc109-43e8-4bd6-a503-ed1099d57a37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 Satoshi's Brain\n",
            "\n",
            "[Scene: Satoshi's study]\n",
            "\n",
            "ASH - [sitting up at an alarming rate, he says] That's what I told him! But he said we could get away with it because Satoshi was still alive...\n",
            "MATHIAS - I hate how he still gets to use that!\n",
            "ASH - Okay, the fact that he was Satoshi means nothing!\n",
            "MATHIAS - Okay, he's alive, right. No body's found him, people still think he's still alive.\n",
            "ASH - But he's not!\n",
            "MATHIAS - I know. You're overreacting.\n",
            "ASH - What?!\n",
            "\n",
            "MATHIAS - Wait, okay, that's it, I've had it! [gets to his feet, begins gathering some things]\n",
            "ASH - Where are you going?!\n",
            "MATHIAS - I'm taking our bitcoin back! And I am also taking all of this. Look at the size of this thing. We're talking about one of the most advanced processors in existence!!\n",
            "ASH - [rising] How much did you tell him about the supercomputer?!\n",
            "MATHIAS - I didn't tell him anything, all he knew was that it had to be built at some point, that's what I told him.\n",
            "ASH - It's the most important component of our plan?!\n",
            "MATHIAS - You're acting like I would do that!\n",
            "ASH - Like it was a crazy idea, like I would just casually show myself in Japan.\n",
            "MATHIAS - It would look better, if you could just be calm about this. I just don't understand how anyone can be so calm about the idea of stealing this thing, it's just like stealing the Mona Lisa.\n"
          ]
        }
      ]
    }
  ]
}