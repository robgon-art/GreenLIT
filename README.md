# **GreenLIT: Using GPT-J with Multi-Task Learning to Create New Screenplays**
## How to fine-tune an ML model to create TV shows and movies with new titles, plot summaries, andÂ scripts

![ReGEN Cover Image](https://raw.githubusercontent.com/robgon-art/ReGEN/main/cover_med.jpg)

Photo by [Tech Daily](https://unsplash.com/photos/PGuCnUzsRSM) on [Unsplash](https://unsplash.com/)</br>

**By Robert. A Gonsalves**</br>

You can see my article on Medium.

The source code and generated images are released under the [CC BY-SA license](https://creativecommons.org/licenses/by-sa/4.0/).</br>
![CC BYC-SA](https://licensebuttons.net/l/by-sa/3.0/88x31.png)

## Google Colabs
* [GreenLIT Generator](https://colab.research.google.com/github/robgon-art/GreenLIT/blob/main/GreenLIT.ipynb)

## Acknowledgements
- GPT-J, Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX (2021)
- R. Caruana, Multitask learning (1997)
- E. Hu, et al., LoRA: Low-rank Adaptation of Large Language Models (2021)
- M. Grootendorst, KeyBERT: Minimal keyword extraction with BERT (2020)

## Citation
To cite this repository:

```bibtex
@software{GreenLIT,
  author  = {Gonsalves, Robert A.},
  title   = {GreenLIT: Using GPT-J with Multi-Task Learning to Create New Screenplays},
  url     = {https://github.com/robgon-art/GreenLIT},
  year    = 2022,
  month   = February
}
```
